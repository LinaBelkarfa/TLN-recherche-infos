{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECHERCHE D'INFORMATION - TLN\n",
    "\n",
    "## Etape 1 — Construction d’un corpus de documents sur le Covid-19  \n",
    "Vous  devez  sauvegarder  le  contenu  textuel  present  dans  les  pages  web  suivantes  (un \n",
    "document txt pour chaque page web) : \n",
    "1. https://www.nature.com/articles/d41586-020-00502-w \n",
    "2. https://www.nejm.org/doi/full/10.1056/NEJMoa2033700?query-featured_coronavirus= \n",
    "3. https://www.nejm.org/doi/full/10.1056/NEJMoa2030340?query=featured_coronavirus \n",
    "4. https://www.nejm.org/doi/full/10.1056/NEJMoa2035002?query-featured_coronavirus= \n",
    "5. https://www.nejm.org/doi/full/10.1056/NEJMoa2029849?query=featured_coronavirus \n",
    "6. https://www.nejm.org/doi/full/10.1056/NEJMpv2035416?query=featured_coronavirus \n",
    "7. https://www.thelancet.com/journals/lanrhe/article/PIIS2665-9913(21)00007-2/fulltext \n",
    "8. https://www.thelancet.com/journals/lanres/article/PIIS2213-2600(21)00025-4/fulltext \n",
    "9. https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)32656-8/fulltext \n",
    "10. https://science.sciencemag.org/content/early/2021/01/11/science.abe6522 \n",
    "\n",
    "* Les légendes des images ne doivent pas être sauvegardées. \n",
    "Le  résultat  de  cette  premiere  étape  est  un  corpus  de  10  documents  en  anglais  sur  le  \n",
    "sujet de la Covid-19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "liste_documents = [\n",
    "    \"https://www.nature.com/articles/d41586-020-00502-w\",\n",
    "    \"https://www.nejm.org/doi/full/10.1056/NEJMoa2033700?query-featured_coronavirus=\",\n",
    "    \"https://www.nejm.org/doi/full/10.1056/NEJMoa2030340?query=featured_coronavirus\",\n",
    "    \"https://www.nejm.org/doi/full/10.1056/NEJMoa2035002?query-featured_coronavirus=\",\n",
    "    \"https://www.nejm.org/doi/full/10.1056/NEJMoa2029849?query=featured_coronavirus\",\n",
    "    \"https://www.nejm.org/doi/full/10.1056/NEJMpv2035416?query=featured_coronavirus\",\n",
    "    \"https://www.thelancet.com/journals/lanrhe/article/PIIS2665-9913(21)00007-2/fulltext\",\n",
    "    \"https://www.thelancet.com/journals/lanres/article/PIIS2213-2600(21)00025-4/fulltext\",\n",
    "    \"https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)32656-8/fulltext\",\n",
    "    \"https://science.sciencemag.org/content/early/2021/01/11/science.abe6522\"]\n",
    "\n",
    "files = [\"Link1.txt\", \"Link2.txt\", \"Link3.txt\",\"Link4.txt\",\"Link5.txt\",\"Link6.txt\",\"Link7.txt\",\"Link8.txt\",\"Link9.txt\",\"Link10.txt\"]\n",
    "\n",
    "nejmOrg = [1,2,3,4,5]\n",
    "thelancet = [6,7,8,9]\n",
    "\n",
    "for i in range(len(liste_documents)):\n",
    "    # read \n",
    "    url = liste_documents[i]\n",
    "\n",
    "    if i == 0 :\n",
    "        page = urlopen(url)\n",
    "        html = page.read().decode(\"utf-8\")\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        text = text.replace(\"  \", \"\")\n",
    "        text = text.replace(\"―\", \"\")\n",
    "        text = str(text).encode(\"utf-8\")\n",
    "\n",
    "    if i in nejmOrg:\n",
    "        source = requests.get(url).text\n",
    "        soup = BeautifulSoup(source,'lxml')   \n",
    "        doc_text = \"\"\n",
    "        for p in soup.body.find_all('p', class_=\"f-body\"):\n",
    "            doc_text+=p.text.strip()\n",
    "        text = str(doc_text).encode(\"utf-8\")\n",
    "\n",
    "    if i in thelancet : \n",
    "        page = requests.get(url).text\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        text = str(text).encode(\"utf-8\")\n",
    "\n",
    "    \n",
    "    names_file = files[i]\n",
    "    file = open(names_file, \"w\") \n",
    "    \n",
    "    #write\n",
    "    file.write(str(text))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Etape 2 — Pre-traitement des données et construction de la matrice d’incidence  \n",
    "\n",
    "L’étape 2 est composée de 5 sous-taches séparées. Vous devez : \n",
    " 1. segmenter chaque document a l’aide d’un tokenizer et extraire les mots (c’est-à-dire couper la séquence de caractères en tokens/segments et les extraire). \n",
    " 2. éliminer les mots-vides (c’est-à-dire enlever les mots très courants, non porteurs de sens). \n",
    " 3. normaliser le vocabulaire des termes a travers la lemmatisation (c’est-à-dire mapper les mots sur les formes du diction \n",
    " 4. définir le dictionnaire relatif à cette collection de documents. \n",
    " 5. vous construisez la matrice d'incidence documents-ter\n",
    " Matrice d’incidence\n",
    "•Idée : créer une structure compacte sur laquelle on va pouvoir effectuer des \n",
    "opérations de recherche.  \n",
    "•Cette structure est une matrice dans laquelle on représente la présence ou \n",
    "non d’un mot dans un document.  \n",
    "•On appelle cela la matrice d’incidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement \n",
    "Je cré ma dataframe avec deux colonnes : \n",
    "* une qui contient le texte du document chargé\n",
    "* l'autre contient le nom du fichier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"COVID research: a year of scientific milesto...</td>\n",
       "      <td>Link1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Therapies to interrupt the progression of ea...</td>\n",
       "      <td>Link2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Coronavirus disease 2019 (Covid-19) pneumoni...</td>\n",
       "      <td>Link3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Recent data suggest that complications and d...</td>\n",
       "      <td>Link4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'Severe acute respiratory syndrome coronaviru...</td>\n",
       "      <td>Link5.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'Covid-19 has devastated refugees and asylum ...</td>\n",
       "      <td>Link6.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b\"COVID-19 and systemic sclerosis: clinicopath...</td>\n",
       "      <td>Link7.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b\"Improving family access to dying patients du...</td>\n",
       "      <td>Link8.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b\"6-month consequences of COVID-19 in patients...</td>\n",
       "      <td>Link9.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b' Immunological characteristics govern the tr...</td>\n",
       "      <td>Link10.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Document\n",
       "0  b\"COVID research: a year of scientific milesto...   Link1.txt\n",
       "1  b'Therapies to interrupt the progression of ea...   Link2.txt\n",
       "2  b'Coronavirus disease 2019 (Covid-19) pneumoni...   Link3.txt\n",
       "3  b'Recent data suggest that complications and d...   Link4.txt\n",
       "4  b'Severe acute respiratory syndrome coronaviru...   Link5.txt\n",
       "5  b'Covid-19 has devastated refugees and asylum ...   Link6.txt\n",
       "6  b\"COVID-19 and systemic sclerosis: clinicopath...   Link7.txt\n",
       "7  b\"Improving family access to dying patients du...   Link8.txt\n",
       "8  b\"6-month consequences of COVID-19 in patients...   Link9.txt\n",
       "9  b' Immunological characteristics govern the tr...  Link10.txt"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "files = [\"Link1.txt\", \"Link2.txt\", \"Link3.txt\",\"Link4.txt\",\"Link5.txt\",\"Link6.txt\",\"Link7.txt\",\"Link8.txt\",\"Link9.txt\",\"Link10.txt\"]\n",
    "\n",
    "documents = pd.DataFrame(columns=['Text', 'Document'])\n",
    "for file in files : \n",
    "    f = open(file)\n",
    "    raw = f.read()\n",
    "    documents = documents.append({'Text': raw, 'Document':file }, ignore_index=True)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Segmenter chaque document à l'aide d'un tokenizer et extraire les mots\n",
    "* J'ajoute une colonne des mots sous forme de token grâce à nlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID research a year of scientific milestones...</td>\n",
       "      <td>Link1.txt</td>\n",
       "      <td>(COVID, research, a, year, of, scientific, mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Therapies to interrupt the progression of earl...</td>\n",
       "      <td>Link2.txt</td>\n",
       "      <td>(Therapies, to, interrupt, the, progression, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease 2019 Covid19 pneumonia is ...</td>\n",
       "      <td>Link3.txt</td>\n",
       "      <td>(Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recent data suggest that complications and dea...</td>\n",
       "      <td>Link4.txt</td>\n",
       "      <td>(Recent, data, suggest, that, complications, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Severe acute respiratory syndrome coronavirus ...</td>\n",
       "      <td>Link5.txt</td>\n",
       "      <td>(Severe, acute, respiratory, syndrome, coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Covid19 has devastated refugees and asylum see...</td>\n",
       "      <td>Link6.txt</td>\n",
       "      <td>(Covid19, has, devastated, refugees, and, asyl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COVID19 and systemic sclerosis clinicopatholog...</td>\n",
       "      <td>Link7.txt</td>\n",
       "      <td>(COVID19, and, systemic, sclerosis, clinicopat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Improving family access to dying patients duri...</td>\n",
       "      <td>Link8.txt</td>\n",
       "      <td>(Improving, family, access, to, dying, patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6month consequences of COVID19 in patients dis...</td>\n",
       "      <td>Link9.txt</td>\n",
       "      <td>(6month, consequences, of, COVID19, in, patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Immunological characteristics govern the tran...</td>\n",
       "      <td>Link10.txt</td>\n",
       "      <td>( , Immunological, characteristics, govern, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Document  \\\n",
       "0  COVID research a year of scientific milestones...   Link1.txt   \n",
       "1  Therapies to interrupt the progression of earl...   Link2.txt   \n",
       "2  Coronavirus disease 2019 Covid19 pneumonia is ...   Link3.txt   \n",
       "3  Recent data suggest that complications and dea...   Link4.txt   \n",
       "4  Severe acute respiratory syndrome coronavirus ...   Link5.txt   \n",
       "5  Covid19 has devastated refugees and asylum see...   Link6.txt   \n",
       "6  COVID19 and systemic sclerosis clinicopatholog...   Link7.txt   \n",
       "7  Improving family access to dying patients duri...   Link8.txt   \n",
       "8  6month consequences of COVID19 in patients dis...   Link9.txt   \n",
       "9   Immunological characteristics govern the tran...  Link10.txt   \n",
       "\n",
       "                                       Tokenize_Text  \n",
       "0  (COVID, research, a, year, of, scientific, mil...  \n",
       "1  (Therapies, to, interrupt, the, progression, o...  \n",
       "2  (Coronavirus, disease, 2019, Covid19, pneumoni...  \n",
       "3  (Recent, data, suggest, that, complications, a...  \n",
       "4  (Severe, acute, respiratory, syndrome, coronav...  \n",
       "5  (Covid19, has, devastated, refugees, and, asyl...  \n",
       "6  (COVID19, and, systemic, sclerosis, clinicopat...  \n",
       "7  (Improving, family, access, to, dying, patient...  \n",
       "8  (6month, consequences, of, COVID19, in, patien...  \n",
       "9  ( , Immunological, characteristics, govern, th...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "import re\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "documents.insert(2,'Tokenize_Text',\"\")\n",
    "\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    documents['Text'][i] = documents['Text'][i][1:]\n",
    "    documents['Text'][i] = re.sub(r'[^\\w\\s]','',documents['Text'][i])\n",
    "    documents['Tokenize_Text'][i] = nlp(documents['Text'][i])\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Eliminer les mots-vides, c'est à dire enlerver les mots très courant, non porteurs de sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "documents.insert(3,'Tokenize_Text_Stop_word',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Je retire les stopwords en anglais, et cré une nouvelle colonne de token sans les stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Tokenize_Text_Stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID research a year of scientific milestones...</td>\n",
       "      <td>Link1.txt</td>\n",
       "      <td>(COVID, research, a, year, of, scientific, mil...</td>\n",
       "      <td>[COVID, research, year, scientific, milestones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Therapies to interrupt the progression of earl...</td>\n",
       "      <td>Link2.txt</td>\n",
       "      <td>(Therapies, to, interrupt, the, progression, o...</td>\n",
       "      <td>[Therapies, interrupt, progression, early, cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease 2019 Covid19 pneumonia is ...</td>\n",
       "      <td>Link3.txt</td>\n",
       "      <td>(Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "      <td>[Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recent data suggest that complications and dea...</td>\n",
       "      <td>Link4.txt</td>\n",
       "      <td>(Recent, data, suggest, that, complications, a...</td>\n",
       "      <td>[Recent, data, suggest, complications, death, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Severe acute respiratory syndrome coronavirus ...</td>\n",
       "      <td>Link5.txt</td>\n",
       "      <td>(Severe, acute, respiratory, syndrome, coronav...</td>\n",
       "      <td>[Severe, acute, respiratory, syndrome, coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Covid19 has devastated refugees and asylum see...</td>\n",
       "      <td>Link6.txt</td>\n",
       "      <td>(Covid19, has, devastated, refugees, and, asyl...</td>\n",
       "      <td>[Covid19, devastated, refugees, asylum, seeker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COVID19 and systemic sclerosis clinicopatholog...</td>\n",
       "      <td>Link7.txt</td>\n",
       "      <td>(COVID19, and, systemic, sclerosis, clinicopat...</td>\n",
       "      <td>[COVID19, systemic, sclerosis, clinicopatholog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Improving family access to dying patients duri...</td>\n",
       "      <td>Link8.txt</td>\n",
       "      <td>(Improving, family, access, to, dying, patient...</td>\n",
       "      <td>[Improving, family, access, dying, patients, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6month consequences of COVID19 in patients dis...</td>\n",
       "      <td>Link9.txt</td>\n",
       "      <td>(6month, consequences, of, COVID19, in, patien...</td>\n",
       "      <td>[6month, consequences, COVID19, patients, disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Immunological characteristics govern the tran...</td>\n",
       "      <td>Link10.txt</td>\n",
       "      <td>( , Immunological, characteristics, govern, th...</td>\n",
       "      <td>[ , Immunological, characteristics, govern, tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Document  \\\n",
       "0  COVID research a year of scientific milestones...   Link1.txt   \n",
       "1  Therapies to interrupt the progression of earl...   Link2.txt   \n",
       "2  Coronavirus disease 2019 Covid19 pneumonia is ...   Link3.txt   \n",
       "3  Recent data suggest that complications and dea...   Link4.txt   \n",
       "4  Severe acute respiratory syndrome coronavirus ...   Link5.txt   \n",
       "5  Covid19 has devastated refugees and asylum see...   Link6.txt   \n",
       "6  COVID19 and systemic sclerosis clinicopatholog...   Link7.txt   \n",
       "7  Improving family access to dying patients duri...   Link8.txt   \n",
       "8  6month consequences of COVID19 in patients dis...   Link9.txt   \n",
       "9   Immunological characteristics govern the tran...  Link10.txt   \n",
       "\n",
       "                                       Tokenize_Text  \\\n",
       "0  (COVID, research, a, year, of, scientific, mil...   \n",
       "1  (Therapies, to, interrupt, the, progression, o...   \n",
       "2  (Coronavirus, disease, 2019, Covid19, pneumoni...   \n",
       "3  (Recent, data, suggest, that, complications, a...   \n",
       "4  (Severe, acute, respiratory, syndrome, coronav...   \n",
       "5  (Covid19, has, devastated, refugees, and, asyl...   \n",
       "6  (COVID19, and, systemic, sclerosis, clinicopat...   \n",
       "7  (Improving, family, access, to, dying, patient...   \n",
       "8  (6month, consequences, of, COVID19, in, patien...   \n",
       "9  ( , Immunological, characteristics, govern, th...   \n",
       "\n",
       "                             Tokenize_Text_Stop_word  \n",
       "0  [COVID, research, year, scientific, milestones...  \n",
       "1  [Therapies, interrupt, progression, early, cor...  \n",
       "2  [Coronavirus, disease, 2019, Covid19, pneumoni...  \n",
       "3  [Recent, data, suggest, complications, death, ...  \n",
       "4  [Severe, acute, respiratory, syndrome, coronav...  \n",
       "5  [Covid19, devastated, refugees, asylum, seeker...  \n",
       "6  [COVID19, systemic, sclerosis, clinicopatholog...  \n",
       "7  [Improving, family, access, dying, patients, C...  \n",
       "8  [6month, consequences, COVID19, patients, disc...  \n",
       "9  [ , Immunological, characteristics, govern, tr...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(documents)):\n",
    "    token = []\n",
    "    for text in  documents['Tokenize_Text'][i] :\n",
    "        if text.text not in stopwords.words('english'):\n",
    "            token.append(text)\n",
    "        documents['Tokenize_Text_Stop_word'][i] = token\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normaliser le vocabulaire des termes à travers la lemmatisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.insert(4,'Lemma',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* J'ajoute une colonne qui prend les mots sans les stops word, et prend les lemme de ces mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(documents)):\n",
    "    lemma = []\n",
    "    for word in range(len(documents['Tokenize_Text_Stop_word'][i])) :\n",
    "        lem = documents['Tokenize_Text_Stop_word'][i][word].lemma_\n",
    "        lemma.append(lem)\n",
    "    documents['Lemma'][i] = lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Tokenize_Text_Stop_word</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID research a year of scientific milestones...</td>\n",
       "      <td>Link1.txt</td>\n",
       "      <td>(COVID, research, a, year, of, scientific, mil...</td>\n",
       "      <td>[COVID, research, year, scientific, milestones...</td>\n",
       "      <td>[COVID, research, year, scientific, milestones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Therapies to interrupt the progression of earl...</td>\n",
       "      <td>Link2.txt</td>\n",
       "      <td>(Therapies, to, interrupt, the, progression, o...</td>\n",
       "      <td>[Therapies, interrupt, progression, early, cor...</td>\n",
       "      <td>[therapy, interrupt, progression, early, coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease 2019 Covid19 pneumonia is ...</td>\n",
       "      <td>Link3.txt</td>\n",
       "      <td>(Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "      <td>[Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "      <td>[Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Document  \\\n",
       "0  COVID research a year of scientific milestones...  Link1.txt   \n",
       "1  Therapies to interrupt the progression of earl...  Link2.txt   \n",
       "2  Coronavirus disease 2019 Covid19 pneumonia is ...  Link3.txt   \n",
       "\n",
       "                                       Tokenize_Text  \\\n",
       "0  (COVID, research, a, year, of, scientific, mil...   \n",
       "1  (Therapies, to, interrupt, the, progression, o...   \n",
       "2  (Coronavirus, disease, 2019, Covid19, pneumoni...   \n",
       "\n",
       "                             Tokenize_Text_Stop_word  \\\n",
       "0  [COVID, research, year, scientific, milestones...   \n",
       "1  [Therapies, interrupt, progression, early, cor...   \n",
       "2  [Coronavirus, disease, 2019, Covid19, pneumoni...   \n",
       "\n",
       "                                               Lemma  \n",
       "0  [COVID, research, year, scientific, milestones...  \n",
       "1  [therapy, interrupt, progression, early, coron...  \n",
       "2  [Coronavirus, disease, 2019, Covid19, pneumoni...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Définir le dictionnaire relatif à cette collection de documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.insert(5,'unique_word',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ici (au cas où) j'ai choisi d'ajouter une colonne avec les lemmes sans doublons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Tokenize_Text_Stop_word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>unique_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID research a year of scientific milestones...</td>\n",
       "      <td>Link1.txt</td>\n",
       "      <td>(COVID, research, a, year, of, scientific, mil...</td>\n",
       "      <td>[COVID, research, year, scientific, milestones...</td>\n",
       "      <td>[COVID, research, year, scientific, milestones...</td>\n",
       "      <td>[['COVID', 'research', 'year', 'scientific', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Therapies to interrupt the progression of earl...</td>\n",
       "      <td>Link2.txt</td>\n",
       "      <td>(Therapies, to, interrupt, the, progression, o...</td>\n",
       "      <td>[Therapies, interrupt, progression, early, cor...</td>\n",
       "      <td>[therapy, interrupt, progression, early, coron...</td>\n",
       "      <td>[['therapy', 'interrupt', 'progression', 'earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease 2019 Covid19 pneumonia is ...</td>\n",
       "      <td>Link3.txt</td>\n",
       "      <td>(Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "      <td>[Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "      <td>[Coronavirus, disease, 2019, Covid19, pneumoni...</td>\n",
       "      <td>[['Coronavirus', 'disease', '2019', 'Covid19',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Document  \\\n",
       "0  COVID research a year of scientific milestones...  Link1.txt   \n",
       "1  Therapies to interrupt the progression of earl...  Link2.txt   \n",
       "2  Coronavirus disease 2019 Covid19 pneumonia is ...  Link3.txt   \n",
       "\n",
       "                                       Tokenize_Text  \\\n",
       "0  (COVID, research, a, year, of, scientific, mil...   \n",
       "1  (Therapies, to, interrupt, the, progression, o...   \n",
       "2  (Coronavirus, disease, 2019, Covid19, pneumoni...   \n",
       "\n",
       "                             Tokenize_Text_Stop_word  \\\n",
       "0  [COVID, research, year, scientific, milestones...   \n",
       "1  [Therapies, interrupt, progression, early, cor...   \n",
       "2  [Coronavirus, disease, 2019, Covid19, pneumoni...   \n",
       "\n",
       "                                               Lemma  \\\n",
       "0  [COVID, research, year, scientific, milestones...   \n",
       "1  [therapy, interrupt, progression, early, coron...   \n",
       "2  [Coronavirus, disease, 2019, Covid19, pneumoni...   \n",
       "\n",
       "                                         unique_word  \n",
       "0  [['COVID', 'research', 'year', 'scientific', '...  \n",
       "1  [['therapy', 'interrupt', 'progression', 'earl...  \n",
       "2  [['Coronavirus', 'disease', '2019', 'Covid19',...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    documents[\"unique_word\"][i]= np.unique(str(documents[\"Lemma\"][i]))\n",
    "\n",
    "documents.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du dictionnaire \n",
    "* Contient le term, le doc dans lequel il se trouve et une colonne nb de fois qui pour le moment est rempli de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Doc n°</th>\n",
       "      <th>nb_fois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57558</th>\n",
       "      <td>ISSN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57559</th>\n",
       "      <td>00368075back</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57560</th>\n",
       "      <td>topterm</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57561</th>\n",
       "      <td>ServicePrivacy</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57562</th>\n",
       "      <td>PolicyAccessibility</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57563 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term Doc n° nb_fois\n",
       "0                    COVID      0       0\n",
       "1                 research      0       0\n",
       "2                     year      0       0\n",
       "3               scientific      0       0\n",
       "4           milestonesSkip      0       0\n",
       "...                    ...    ...     ...\n",
       "57558                 ISSN      9       0\n",
       "57559         00368075back      9       0\n",
       "57560              topterm      9       0\n",
       "57561       ServicePrivacy      9       0\n",
       "57562  PolicyAccessibility      9       0\n",
       "\n",
       "[57563 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dictionnaire = pd.DataFrame( columns=[\"Term\", \"Doc n°\",\"nb_fois\"])\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    texte = documents[\"Lemma\"][i]\n",
    "\n",
    "    for mot in texte :\n",
    "        Dictionnaire = Dictionnaire.append({\"Term\": mot,\"Doc n°\":i , \"nb_fois\":0}, ignore_index=True)\n",
    "\n",
    "Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On retire les doublons, car des mots sont présent plusieurs fois dans un document, on enlève donc les lignes dont le term et le doc sont identiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionnaire = Dictionnaire.drop_duplicates(subset=None, \n",
    "                          keep='first', \n",
    "                          inplace=False, \n",
    "                          ignore_index=True) # on retire les doublons \n",
    "# c'est à dire, les lignes dont le mot et le doc sont similaire \n",
    "# (on a pas encore compté les occurences donc elles sont toutes à 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptage du nombre d'occurence de chaque mot dans chaque doc\n",
    "* Cela pourra nous être utile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Doc n°</th>\n",
       "      <th>nb_fois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>COUNTER</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16955</th>\n",
       "      <td>ISSN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16956</th>\n",
       "      <td>00368075back</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>topterm</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958</th>\n",
       "      <td>PolicyAccessibility</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16959 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term Doc n° nb_fois\n",
       "0                    COVID      0      35\n",
       "1                 research      0      19\n",
       "2                     year      0      14\n",
       "3               scientific      0       2\n",
       "4           milestonesSkip      0       1\n",
       "...                    ...    ...     ...\n",
       "16954              COUNTER      9       1\n",
       "16955                 ISSN      9       1\n",
       "16956         00368075back      9       1\n",
       "16957              topterm      9       1\n",
       "16958  PolicyAccessibility      9       1\n",
       "\n",
       "[16959 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut commencer à compter les occurrences \n",
    "for i in range(len(Dictionnaire)): # pour chaque mot et document associé\n",
    "    doc = Dictionnaire['Doc n°'][i]\n",
    "    Term =  Dictionnaire['Term'][i]\n",
    "    for j in range(len(documents)): # pour chaque document correspondant à la ligne du dict\n",
    "        if j == doc: \n",
    "            for word in documents[\"Lemma\"][j]:\n",
    "                if word == Term: \n",
    "                    Dictionnaire.at[i,'nb_fois'] +=1\n",
    "            \n",
    "            \n",
    "Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association des termes et document \n",
    "* Dictionnaire final contenant : \n",
    "    - Le term\n",
    "    - Le doc dans lequel il se trouve\n",
    "    - Le nombre de fois qu'il y apparaît\n",
    "    - **Le nombre de document dans lequel il apparaît**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionnaire.insert(3,'nb_de_Doc',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Doc n°</th>\n",
       "      <th>nb_fois</th>\n",
       "      <th>nb_de_Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>COUNTER</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16955</th>\n",
       "      <td>ISSN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16956</th>\n",
       "      <td>00368075back</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>topterm</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958</th>\n",
       "      <td>PolicyAccessibility</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term Doc n° nb_fois nb_de_Doc\n",
       "0                    COVID      0      35         4\n",
       "1                 research      0      19         4\n",
       "2                     year      0      14         8\n",
       "3               scientific      0       2         1\n",
       "4           milestonesSkip      0       1         1\n",
       "...                    ...    ...     ...       ...\n",
       "16954              COUNTER      9       1         1\n",
       "16955                 ISSN      9       1         1\n",
       "16956         00368075back      9       1         1\n",
       "16957              topterm      9       1         1\n",
       "16958  PolicyAccessibility      9       1         1\n",
       "\n",
       "[16959 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajout de la colonne qui compte le nombre de doc dans lesquels le terme apparait\n",
    "for i in range(len(Dictionnaire)):\n",
    "    term = Dictionnaire['Term'][i]\n",
    "    lign = Dictionnaire[Dictionnaire['Term']== term].index\n",
    "    Dictionnaire.at[i, 'nb_de_Doc'] = len(lign)\n",
    "\n",
    "Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Construire la matrice d'incidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Je cré d'abord une matrice de zéro (la largeur prend le nombre de doc + le term, et la longueur sera la nombre de term )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11393</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11394</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11396</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11398 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Term    0    1    2    3    4    5    6    7    8    9\n",
       "0           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "11393       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11394       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11395       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11396       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11397       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[11398 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrice_incidence = np.zeros((len(np.unique(Dictionnaire['Term'])),len(np.unique(Dictionnaire['Doc n°']))))\n",
    "Matrice_incidence_df = pd.DataFrame(Matrice_incidence)\n",
    "Matrice_incidence_df.insert(0, \"Term\", \"\")\n",
    "Matrice_incidence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* je remplis ma matrice d'incidence \n",
    "* comme j'ai des mots qui sont des espaces (dû au chargement des urls qui font des espaces de tailles différentes), je prend soin de ne prendre que les mots qui ne sont pas des espaces ou tabulation uniquement grace à **.isspace()**\n",
    "* on met 1 lorsque le mot est dans le doc et 0 sinon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11393</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11394</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11396</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11398 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Term    0    1    2    3    4    5    6    7    8    9\n",
       "0               COVID  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "1            research  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0\n",
       "2                year  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0\n",
       "3          scientific  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4      milestonesSkip  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...               ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "11393                  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11394                  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11395                  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11396                  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11397                  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[11398 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "list_of_term = []\n",
    "\n",
    "for term in Dictionnaire['Term']:\n",
    "    if term.isspace()==False and term not in list_of_term: # si ce n'est pas un espace\n",
    "        Matrice_incidence_df.at[i,'Term']= term #je met dans la matrice d'incidence le term\n",
    "        list_of_term.append(term)\n",
    "        for doc in range(0,10): \n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== term) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            if len(lign) !=0 :\n",
    "                lign.reset_index(inplace=True, drop=False)\n",
    "\n",
    "                if lign['nb_fois'][0]!=0:\n",
    "                    Matrice_incidence_df.at[i,doc]=1\n",
    "        i += 1 \n",
    "\n",
    "Matrice_incidence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comme il y avait des mots \"espaces\", je dois retirer les lignes qui n'ont pas de term pour obtenir ma matrice final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>COUNTER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>ISSN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>00368075back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>topterm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>PolicyAccessibility</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11382 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term    0    1    2    3    4    5    6    7    8    9\n",
       "0                    COVID  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "1                 research  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0\n",
       "2                     year  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0\n",
       "3               scientific  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4           milestonesSkip  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...                    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "11377              COUNTER  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11378                 ISSN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11379         00368075back  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11380              topterm  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11381  PolicyAccessibility  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "\n",
       "[11382 rows x 11 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexMat = Matrice_incidence_df[Matrice_incidence_df['Term']==\"\"].index\n",
    "Matrice_incidence_df.drop(indexMat , inplace=True)\n",
    "Matrice_incidence_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partir d'ici il est possible de tout charger depuis les fichiers : \n",
    "* Dictionnaire.pkl --> le dictionnaire créé \n",
    "* Matrice_incidence_df.pkl --> la matrice d'incidence créé\n",
    "* Documents.pkl --> la dataframe des documents complets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarder en Dataframe grace à .pkl\n",
    "#Dictionnaire.to_pickle('Dictionnaire.pkl')  \n",
    "#Matrice_incidence_df.to_pickle('Matrice_incidence_df.pkl')  \n",
    "#Pour recharger les dataframe : \n",
    "import pandas as pd\n",
    "Dictionnaire = pd.read_pickle('Dictionnaire.pkl')\n",
    "Matrice_incidence_df = pd.read_pickle('Matrice_incidence_df.pkl')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_doc=documents.loc[:,documents.columns!=\"Tokenize_Text\"]\n",
    "#filtered_doc = filtered_doc.loc[:,filtered_doc.columns!=\"Tokenize_Text_Stop_word\"]\n",
    "#filtered_doc.to_pickle('Documents.pkl')\n",
    "#écriture de df documents sans les token car non supporté par .pkl\n",
    "documents = pd.read_pickle('Documents.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>COUNTER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>ISSN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>00368075back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>topterm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>PolicyAccessibility</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11382 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term    0    1    2    3    4    5    6    7    8    9\n",
       "0                    COVID  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "1                 research  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0\n",
       "2                     year  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0\n",
       "3               scientific  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4           milestonesSkip  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...                    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "11377              COUNTER  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11378                 ISSN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11379         00368075back  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11380              topterm  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "11381  PolicyAccessibility  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "\n",
       "[11382 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrice_incidence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 — Construction de l’index inversé\n",
    "* Après la construction de la matrice d'incidence documents-termes, vous devez construire l'index inversé (liste variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dictionnaire = {}\n",
    "\n",
    "for i in range(len(Matrice_incidence_df['Term'])) : \n",
    "    doc = []\n",
    "    for j in range(0,10): \n",
    "        if Matrice_incidence_df[j][i] == 1 :\n",
    "           doc.append(j) \n",
    "    index_dictionnaire.update({ Matrice_incidence_df['Term'][i] : doc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COVID': [0, 7, 8, 9],\n",
       " 'research': [0, 2, 8, 9],\n",
       " 'year': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'scientific': [0],\n",
       " 'milestonesSkip': [0],\n",
       " 'main': [0, 8],\n",
       " 'contentthank': [0],\n",
       " 'visit': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'naturecom': [0],\n",
       " '-PRON-': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'use': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'browser': [0],\n",
       " 'version': [0, 2, 3, 8, 9],\n",
       " 'limited': [0, 2, 5, 6, 7, 8],\n",
       " 'support': [0, 1, 2, 3, 4, 7, 8],\n",
       " 'css': [0],\n",
       " 'to': [0, 2, 6, 7, 8, 9],\n",
       " 'obtainthe': [0],\n",
       " 'good': [0, 3, 5, 7, 8, 9],\n",
       " 'experience': [0, 3, 5, 7, 9],\n",
       " 'recommend': [0, 2, 5, 7],\n",
       " 'date': [0, 2, 8, 9],\n",
       " 'turn': [0, 7, 9],\n",
       " 'compatibility': [0],\n",
       " 'mode': [0],\n",
       " 'inInternet': [0],\n",
       " 'Explorer': [0],\n",
       " 'in': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'meantime': [0],\n",
       " 'ensure': [0, 2, 4, 8],\n",
       " 'continued': [0, 9],\n",
       " 'display': [0],\n",
       " 'site': [0, 1, 2, 3, 6, 7, 8],\n",
       " 'without': [0, 2, 5, 6, 7, 8, 9],\n",
       " 'stylesand': [0],\n",
       " 'JavaScriptAdvertisementView': [0],\n",
       " 'journalsSearchMy': [0],\n",
       " 'AccountLoginExplore': [0],\n",
       " 'contentabout': [0],\n",
       " 'journalpublish': [0],\n",
       " 'ussubscribesign': [0],\n",
       " 'alertsRSS': [0],\n",
       " 'feednaturenewsarticleNEWS05': [0],\n",
       " 'May': [0, 8],\n",
       " '2021covid': [0],\n",
       " 'milestonesnature': [0],\n",
       " 'wade': [0],\n",
       " 'literature': [0, 6, 8, 9],\n",
       " 'coronavirus': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'xe2x80x94': [0, 2, 3, 4, 5],\n",
       " 'summarize': [0],\n",
       " 'key': [0, 2, 3, 4, 9],\n",
       " 'paper': [0, 1, 9],\n",
       " 'appearedTwitterFacebookEmailYou': [0],\n",
       " 'full': [0, 1, 2, 3, 4, 8, 9],\n",
       " 'access': [0, 1, 2, 3, 6, 7, 8, 9],\n",
       " 'article': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'via': [0, 8, 9],\n",
       " 'institutiondownload': [0],\n",
       " 'pdfa': [0],\n",
       " 'cell': [0, 3, 4, 6, 8, 9],\n",
       " 'infect': [0, 1, 3, 4, 8, 9],\n",
       " 'particle': [0],\n",
       " 'yellow': [0],\n",
       " 'artificially': [0],\n",
       " 'colour': [0],\n",
       " 'SARSCoV2': [0, 1, 2, 3, 4, 5, 6, 8, 9],\n",
       " 'variant': [0, 4, 9],\n",
       " 'call': [0, 7],\n",
       " 'b117': [0],\n",
       " 'easily': [0],\n",
       " 'transmit': [0],\n",
       " 'viruscredit': [0],\n",
       " 'National': [0, 2, 4, 5, 8, 9],\n",
       " 'Institutes': [0],\n",
       " 'HealthScience': [0],\n",
       " 'Photo': [0, 7],\n",
       " 'LibraryFor': [0],\n",
       " 'COVID19': [0, 1, 2, 6, 7, 8, 9],\n",
       " 'pandemic': [0, 1, 2, 4, 5, 6, 7, 8, 9],\n",
       " 'Nature': [0, 9],\n",
       " 'highlight': [0, 8, 9],\n",
       " 'preprint': [0],\n",
       " 'help': [0, 2, 4, 6, 7, 8],\n",
       " 'reader': [0],\n",
       " 'keep': [0, 6],\n",
       " 'flood': [0],\n",
       " 'those': [0],\n",
       " 'for': [0, 1, 3, 4, 8, 9],\n",
       " 'continue': [0, 1, 2, 3, 4, 9],\n",
       " 'coverage': [0, 4],\n",
       " 'important': [0, 1, 3, 4, 8, 9],\n",
       " 'development': [0, 1, 3, 8, 9],\n",
       " 'go': [0],\n",
       " 'Naturexe2x80x99s': [0],\n",
       " 'news': [0],\n",
       " 'sectionA': [0],\n",
       " 'healthcare': [0, 6, 7, 8, 9],\n",
       " 'worker': [0, 5],\n",
       " 'prepare': [0, 1, 2],\n",
       " 'dose': [0, 2, 3, 4],\n",
       " 'AstraZeneca': [0],\n",
       " 'vaccine': [0, 1, 5, 7, 9],\n",
       " 'woman': [0, 1, 6, 7, 8],\n",
       " 'Hasland': [0],\n",
       " 'UKCredit': [0],\n",
       " 'Oli': [0],\n",
       " 'ScarffAFPGetty30': [0],\n",
       " 'April': [0, 6, 7, 9],\n",
       " 'one': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'nearly': [0, 4, 8],\n",
       " 'halve': [0],\n",
       " 'transmission': [0, 7, 8, 9],\n",
       " 'riska': [0],\n",
       " 'single': [0, 3, 4, 7, 9],\n",
       " 'make': [0, 2, 3, 8, 9],\n",
       " 'either': [0, 1, 2, 3, 4],\n",
       " 'Pfizer': [0, 5],\n",
       " 'cut': [0],\n",
       " 'personxe2x80x99s': [0],\n",
       " 'risk': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'sarscov2': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'close': [0, 5, 6, 7, 9],\n",
       " 'contact': [0, 2, 6, 8, 9],\n",
       " 'much': [0, 7, 9],\n",
       " 'half': [0],\n",
       " 'accord': [0, 2, 3, 4, 6, 8],\n",
       " 'analysis': [0, 1, 2, 3, 4, 8, 9],\n",
       " '365000': [0],\n",
       " 'household': [0],\n",
       " 'United': [0, 2, 4, 9],\n",
       " 'KingdomAlthough': [0],\n",
       " 'show': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'reduce': [0, 1, 2, 3, 4, 7, 8, 9],\n",
       " 'covid19': [0, 5, 6, 7, 8, 9],\n",
       " 'symptom': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'serious': [0, 1, 2, 3, 6, 9],\n",
       " 'illness': [0, 1, 2, 4, 5, 8],\n",
       " 'ability': [0],\n",
       " 'prevent': [0, 1, 3, 4, 5, 9],\n",
       " 'unclear': [0, 4, 8],\n",
       " 'Kevin': [0],\n",
       " 'Dunbar': [0],\n",
       " 'Gavin': [0],\n",
       " 'Dabrera': [0],\n",
       " 'colleague': [0, 8],\n",
       " 'Public': [0, 6, 7, 8, 9],\n",
       " 'Health': [0, 3, 6, 7, 8, 9],\n",
       " 'England': [0, 2],\n",
       " 'London': [0, 9],\n",
       " 'look': [0],\n",
       " 'case': [0, 1, 2, 5, 6, 7, 8, 9],\n",
       " 'someone': [0],\n",
       " 'become': [0, 1, 2, 3, 4, 5, 9],\n",
       " 'receive': [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'R': [0, 7, 8, 9],\n",
       " 'J': [0, 6, 7, 8, 9],\n",
       " 'Harris': [0],\n",
       " 'et': [0, 6, 7, 8, 9],\n",
       " 'al': [0, 9],\n",
       " 'Preprint': [0, 9],\n",
       " 'Knowledge': [0],\n",
       " 'Hub': [0],\n",
       " 'httpsgonaturecom3e3iu1i': [0],\n",
       " '2021': [0, 6, 7, 8, 9],\n",
       " 'assess': [0, 1, 2, 3, 4, 7, 8, 9],\n",
       " 'often': [0, 2, 6, 7],\n",
       " 'individual': [0, 3, 5, 6, 7, 8, 9],\n",
       " 'virus': [0, 1, 2, 3, 4, 5, 8, 9],\n",
       " 'contactsThe': [0],\n",
       " 'team': [0, 1, 8],\n",
       " 'find': [0, 2, 3, 6, 7, 8, 9],\n",
       " 'people': [0, 5, 7, 8, 9],\n",
       " 'vaccinate': [0, 5, 9],\n",
       " 'least': [0, 1, 2, 3, 4, 5, 6, 8, 9],\n",
       " '21': [0, 2, 4, 6, 8, 9],\n",
       " 'day': [0, 1, 2, 3, 4, 7, 8, 9],\n",
       " 'could': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'still': [0, 7, 8, 9],\n",
       " 'test': [0, 1, 2, 3, 4, 5, 6, 8, 9],\n",
       " 'positive': [0, 1, 2, 3, 4, 6, 8],\n",
       " 'but': [0, 7],\n",
       " 'viral': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'other': [0, 1, 8, 9],\n",
       " '40xe2x80x9350': [0],\n",
       " 'low': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'first': [0, 1, 2, 3, 8, 9],\n",
       " 'person': [0, 1, 2, 3, 4, 9],\n",
       " 'result': [0, 1, 2, 3, 4, 5, 6, 8, 9],\n",
       " 'two': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'similar': [0, 2, 3, 4, 8, 9],\n",
       " 'the': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'finding': [0, 1, 3, 4, 6, 8, 9],\n",
       " 'yet': [0, 2, 3, 4, 8, 9],\n",
       " 'peer': [0, 9],\n",
       " 'reviewedA': [0],\n",
       " 'lie': [0],\n",
       " 'intensivecare': [0],\n",
       " 'unit': [0, 1, 2, 7, 8],\n",
       " 'SantiagoCredit': [0],\n",
       " 'Martin': [0],\n",
       " 'BernettiAFPGetty29': [0],\n",
       " 'a': [0, 1, 3, 4, 8, 9],\n",
       " 'chilean': [0],\n",
       " 'cityxe2x80x99s': [0],\n",
       " 'covid': [0],\n",
       " 'toll': [0, 9],\n",
       " 'reflect': [0, 2],\n",
       " 'vast': [0],\n",
       " 'inequalitiesIn': [0],\n",
       " 'Santiago': [0],\n",
       " 'deal': [0, 9],\n",
       " 'hard': [0, 7, 9],\n",
       " 'blow': [0],\n",
       " 'socioeconomic': [0, 2],\n",
       " 'status': [0, 1, 2, 3, 8, 9],\n",
       " 'factor': [0, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'crowd': [0],\n",
       " 'lack': [0, 1, 3, 5],\n",
       " 'health': [0, 1, 2, 5, 7, 8, 9],\n",
       " 'care': [0, 1, 2, 3, 4, 5, 7, 8],\n",
       " 'inability': [0],\n",
       " 'work': [0, 1, 5, 8, 9],\n",
       " 'homedeath': [0],\n",
       " 'rate': [0, 1, 2, 4, 5, 7, 8, 9],\n",
       " 'great': [0, 1, 2, 3, 5, 7, 8],\n",
       " 'lowincome': [0],\n",
       " 'area': [0, 2, 3, 9],\n",
       " 'especially': [0, 2, 9],\n",
       " 'among': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'age': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " '80': [0, 1, 2, 3, 4, 8],\n",
       " 'highincome': [0],\n",
       " 'Gonzalo': [0],\n",
       " 'Mena': [0],\n",
       " 'Harvard': [0],\n",
       " 'TH': [0],\n",
       " 'Chan': [0],\n",
       " 'School': [0, 5, 6, 8, 9],\n",
       " 'Boston': [0, 2],\n",
       " 'Massachusetts': [0],\n",
       " 'G': [0, 7, 8, 9],\n",
       " 'E': [0, 8, 9],\n",
       " 'Science': [0, 8, 9],\n",
       " 'httpsdoiorgf9b4': [0],\n",
       " 'several': [0, 1, 3, 4, 5, 8, 9],\n",
       " 'explanation': [0],\n",
       " 'disparity': [0, 2],\n",
       " 'compare': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'higherincome': [0],\n",
       " 'lowerincome': [0],\n",
       " 'neighborhood': [0],\n",
       " 'high': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'this': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'suggest': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'inadequate': [0, 5],\n",
       " 'therefore': [0, 1, 2, 3, 4, 6, 9],\n",
       " 'effort': [0, 8],\n",
       " 'base': [0, 3, 4, 9],\n",
       " 'number': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'curb': [0, 9],\n",
       " 'epidemic': [0, 9],\n",
       " 'couldnxe2x80x99': [0],\n",
       " 'appropriately': [0, 8],\n",
       " 'targetedLowincome': [0],\n",
       " 'onequarter': [0],\n",
       " 'many': [0, 1, 4, 7, 9],\n",
       " 'hospital': [0, 1, 2, 4, 6, 7, 8, 9],\n",
       " 'bed': [0],\n",
       " 'per': [0, 1, 2, 3, 4, 6, 8],\n",
       " '10000': [0],\n",
       " 'wealthy': [0],\n",
       " 'and': [0, 8, 9],\n",
       " 'striking': [0],\n",
       " '90': [0, 2, 3, 5, 8],\n",
       " 'death': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'occur': [0, 1, 2, 3, 4, 7, 8, 9],\n",
       " 'outside': [0, 7, 8],\n",
       " 'facility': [0, 5, 7],\n",
       " '55': [0, 1],\n",
       " 'affluent': [0],\n",
       " 'capitalfinally': [0],\n",
       " 'location': [0],\n",
       " 'datum': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'mobile': [0],\n",
       " 'phone': [0],\n",
       " 'move': [0, 8, 9],\n",
       " 'period': [0, 1, 2, 3, 6, 8, 9],\n",
       " 'resident': [0, 1, 2, 5, 6, 9],\n",
       " 'suppose': [0, 9],\n",
       " 'stay': [0, 8],\n",
       " 'home': [0, 1, 5, 7, 8],\n",
       " 'possibly': [0, 8, 9],\n",
       " 'job': [0],\n",
       " 'houseTwo': [0],\n",
       " 'swab': [0, 3, 4, 6],\n",
       " 'testing': [0, 1, 3, 4, 6, 8, 9],\n",
       " 'centre': [0, 6],\n",
       " 'LondonCredit': [0],\n",
       " 'Daniel': [0],\n",
       " 'LealOlivasAFPGetty28': [0],\n",
       " 'Selftaken': [0],\n",
       " 'track': [0],\n",
       " 'pandemicxe2x80x99s': [0],\n",
       " 'hide': [0, 6, 7, 8],\n",
       " 'pattern': [0, 2, 8, 9],\n",
       " 'regular': [0, 6],\n",
       " 'swabbing': [0],\n",
       " 'random': [0, 8],\n",
       " 'sample': [0, 1, 3, 4, 8],\n",
       " 'population': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'quickly': [0, 7, 9],\n",
       " 'detect': [0, 1, 2],\n",
       " 'resurgence': [0],\n",
       " 'infection': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'even': [0, 3, 4, 7, 8, 9],\n",
       " 'young': [0, 8, 9],\n",
       " 'adultssteven': [0],\n",
       " 'Riley': [0, 9],\n",
       " 'Paul': [0],\n",
       " 'Elliott': [0],\n",
       " 'Imperial': [0],\n",
       " 'College': [0, 8],\n",
       " 'nose': [0],\n",
       " 'throat': [0, 1, 8],\n",
       " '594000': [0],\n",
       " 'randomly': [0, 1, 2, 3, 4],\n",
       " 'select': [0, 1, 3, 8, 9],\n",
       " 'UK': [0, 9],\n",
       " 'child': [0, 5, 9],\n",
       " '1': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " '8': [0, 1, 2, 7, 9],\n",
       " 'September': [0, 2, 3, 4, 9],\n",
       " '2020': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'S': [0, 1, 6, 7, 8, 9],\n",
       " 'httpsdoiorgf8rx': [0],\n",
       " 'study': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'time': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'dip': [0],\n",
       " '004': [0],\n",
       " 'around': [0, 9],\n",
       " '5': [0, 1, 2, 3, 4, 8, 9],\n",
       " 'early': [0, 1, 2, 3, 4, 7, 8, 9],\n",
       " 'height': [0, 4],\n",
       " 'Kingdomxe2x80x99s': [0],\n",
       " 'wave': [0, 9],\n",
       " 'begin': [0, 9],\n",
       " 'climb': [0],\n",
       " 'peak': [0, 9],\n",
       " '013': [0],\n",
       " 'final': [0, 3, 7, 8],\n",
       " 'round': [0],\n",
       " 'testingprevalence': [0],\n",
       " 'second': [0, 8],\n",
       " 'adult': [0, 1, 5, 7, 8, 9],\n",
       " '18xe2x80x9324': [0],\n",
       " '025': [0, 4],\n",
       " '65': [0, 1, 2, 4],\n",
       " 'old': [0, 1, 2, 3, 4, 5, 9],\n",
       " 'increase': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'socialize': [0],\n",
       " 'probably': [0],\n",
       " 'drive': [0, 1, 3, 4],\n",
       " 'these': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'routine': [0, 7],\n",
       " 'surveillance': [0, 9],\n",
       " 'healthservice': [0],\n",
       " 'provider': [0, 6],\n",
       " 'underestimate': [0, 6, 8],\n",
       " 'groupsThe': [0, 2, 3],\n",
       " 'researcher': [0, 4, 8],\n",
       " 'say': [0, 7],\n",
       " 'demonstrate': [0],\n",
       " 'benefit': [0, 1, 2, 3, 7, 8],\n",
       " 'largescale': [0, 9],\n",
       " 'community': [0, 5, 7, 9],\n",
       " 'provide': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'warning': [0, 7],\n",
       " 'spike': [0, 1, 3, 4, 8, 9],\n",
       " 'level': [0, 1, 2, 4, 5, 7, 8, 9],\n",
       " 'transmissionA': [0],\n",
       " 'red': [0],\n",
       " 'colouredcredit': [0],\n",
       " 'Library27': [0],\n",
       " 'how': [0, 7, 9],\n",
       " 'predict': [0, 3, 4, 8, 9],\n",
       " 'vaccinexe2x80x99s': [0],\n",
       " 'success': [0],\n",
       " 'large': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'trialModernaxe2x80x99s': [0],\n",
       " 'protection': [0, 1, 2, 4, 5, 9],\n",
       " 'trigger': [0, 4],\n",
       " 'production': [0],\n",
       " 'antibody': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'protein': [0, 1, 3, 4, 8, 9],\n",
       " 'monkey': [0],\n",
       " 'insight': [0, 6, 9],\n",
       " 'confirm': [0, 2, 3, 4, 6, 8],\n",
       " 'human': [0, 2, 3, 5, 9],\n",
       " 'speed': [0],\n",
       " 'nextgeneration': [0],\n",
       " 'vaccinesvaccine': [0],\n",
       " 'diverse': [0],\n",
       " 'immune': [0, 2, 3, 6, 9],\n",
       " 'response': [0, 2, 3, 4, 7, 8, 9],\n",
       " 'include': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'manufacture': [0],\n",
       " 'molecule': [0, 9],\n",
       " 'bind': [0, 4, 8, 9],\n",
       " 'block': [0, 1, 9],\n",
       " 'infectious': [0, 4, 5, 8, 9],\n",
       " 'activation': [0, 8, 9],\n",
       " 't': [0, 7, 9],\n",
       " 'kill': [0, 9],\n",
       " 'virusinfecte': [0],\n",
       " 'by': [0, 1, 3, 5, 9],\n",
       " 'identify': [0, 1, 2, 3, 8, 9],\n",
       " 'scientist': [0],\n",
       " 'judge': [0],\n",
       " 'candidate': [0, 1],\n",
       " 'vaccinesto': [0],\n",
       " 'Modernaxe2x80x99s': [0],\n",
       " 'Barney': [0],\n",
       " 'Graham': [0, 9],\n",
       " 'Robert': [0],\n",
       " 'Seder': [0],\n",
       " 'US': [0, 1, 5, 9],\n",
       " 'Institute': [0, 2, 3, 4, 6, 8, 9],\n",
       " 'Allergy': [0, 4, 9],\n",
       " 'Infectious': [0, 4, 6, 7, 8, 9],\n",
       " 'Diseases': [0, 4, 6, 8],\n",
       " 'Bethesda': [0],\n",
       " 'Maryland': [0, 5],\n",
       " 'give': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'range': [0, 1, 2, 3, 4, 8, 9],\n",
       " 'expose': [0],\n",
       " 'animal': [0, 4, 9],\n",
       " 'K': [0, 8, 9],\n",
       " 'Corbett': [0],\n",
       " 'biorxiv': [0, 9],\n",
       " 'httpsdoiorgf8pf': [0],\n",
       " 'vaccinated': [0, 9],\n",
       " 'genetic': [0, 6, 9],\n",
       " 'material': [0, 9],\n",
       " 'lung': [0, 4, 6, 8, 9],\n",
       " 'also': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'recognize': [0, 9],\n",
       " 'Moderna': [0, 5],\n",
       " 'encode': [0],\n",
       " 'Levels': [0],\n",
       " 'marker': [0, 4],\n",
       " 'correlate': [0, 1, 2, 3, 4, 6, 9],\n",
       " 'strongly': [0, 3, 9],\n",
       " 'protective': [0, 7, 9],\n",
       " 'effect': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'parallel': [0, 9],\n",
       " 'way': [0, 2, 4, 8, 9],\n",
       " 'protect': [0, 3, 9],\n",
       " 'jab': [0],\n",
       " 'despite': [0, 2, 3, 7],\n",
       " 'xe2x80x98correlates': [0],\n",
       " 'protectionxe2x80x99': [0],\n",
       " 'existing': [0],\n",
       " 'future': [0, 1, 3, 4, 8, 9],\n",
       " 'run': [0, 9],\n",
       " 'costly': [0],\n",
       " 'clinical': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'trialsresident': [0],\n",
       " 'senior': [0],\n",
       " 'Anaheim': [0],\n",
       " 'California': [0],\n",
       " 'vaccinationcredit': [0],\n",
       " 'bersebachmedianews': [0],\n",
       " 'GroupOrange': [0],\n",
       " 'County': [0],\n",
       " 'RegisterGetty23': [0],\n",
       " 'carehome': [0],\n",
       " 'outbreak': [0, 1, 5, 6, 7, 8, 9],\n",
       " 'powersin': [0],\n",
       " 'realworld': [0],\n",
       " 'mRNAbased': [0],\n",
       " 'staff': [0, 5, 7, 8, 9],\n",
       " 'new': [0, 2, 7, 8, 9],\n",
       " 'variantOn': [0],\n",
       " 'March': [0, 6],\n",
       " 'unvaccinated': [0],\n",
       " 'Kentucky': [0],\n",
       " 'at': [0, 1, 3, 5, 9],\n",
       " 'homexe2x80x99s': [0],\n",
       " '53': [0, 2],\n",
       " 'Pfizerxe2x80x93BioNTech': [0],\n",
       " 'majority': [0, 4, 6],\n",
       " 'shot': [0],\n",
       " '2': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'week': [0, 7, 9],\n",
       " 'workerxe2x80x99s': [0],\n",
       " 'identifiedalyson': [0],\n",
       " 'Cavanaugh': [0],\n",
       " 'Centers': [0, 2, 5],\n",
       " 'Disease': [0, 2, 5, 8, 9],\n",
       " 'Control': [0, 2, 5, 9],\n",
       " 'Prevention': [0, 2, 5, 9],\n",
       " 'report': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " '46': [0, 7],\n",
       " '199': [0],\n",
       " 'A': [0, 5, 8, 9],\n",
       " 'M': [0, 6, 7, 8, 9],\n",
       " 'Morb': [0],\n",
       " 'Mortal': [0],\n",
       " 'Wkly': [0],\n",
       " 'Rep': [0],\n",
       " 'httpsdoiorgf732': [0],\n",
       " 'estimate': [0, 1, 2, 3, 4, 8, 9],\n",
       " '865': [0],\n",
       " '871': [0],\n",
       " 'effective': [0, 1, 3, 5, 6, 9],\n",
       " 'respectively': [0, 1, 2, 3, 4, 9],\n",
       " 'past': [0],\n",
       " 'hospitalization': [0, 1, 2, 3, 4],\n",
       " 'although': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'diedgenome': [0],\n",
       " 'sequencing': [0],\n",
       " '27': [0, 1, 6, 8, 9],\n",
       " 'circulating': [0],\n",
       " 'know': [0, 4, 5, 7, 9],\n",
       " 'R1': [0],\n",
       " 'contain': [0, 3, 4, 6, 7, 8, 9],\n",
       " 'mutation': [0, 9],\n",
       " 'link': [0, 4, 6, 7, 8],\n",
       " 'transmissibility': [0, 9],\n",
       " 'evasionA': [0],\n",
       " 'pink': [0],\n",
       " 'artificiallly': [0],\n",
       " 'Library22': [0],\n",
       " 'previous': [0, 1, 3, 7, 8, 9],\n",
       " 'shorten': [0],\n",
       " 'illnessrecent': [0],\n",
       " 'relate': [0, 1, 3, 8, 9],\n",
       " 'duration': [0, 1, 6, 7, 8, 9],\n",
       " '2000': [0],\n",
       " 'workersantibodie': [0],\n",
       " 'powerful': [0],\n",
       " 'defence': [0],\n",
       " 'rare': [0],\n",
       " 'coronaviruse': [0, 9],\n",
       " 'predate': [0],\n",
       " 'search': [0, 6, 7, 8],\n",
       " 'possible': [0, 3, 4, 6, 9],\n",
       " 'Scott': [0],\n",
       " 'Hensley': [0],\n",
       " 'University': [0, 6, 7, 8, 9],\n",
       " 'Pennsylvania': [0, 9],\n",
       " 'Philadelphia': [0],\n",
       " 'local': [0, 2, 3, 9],\n",
       " 'volunteer': [0, 9],\n",
       " 'surge': [0, 9],\n",
       " 'Gouma': [0],\n",
       " 'medRxiv': [0],\n",
       " 'httpsdoiorgf7zp': [0],\n",
       " '2021the': [0],\n",
       " 'prepandemic': [0],\n",
       " 'contract': [0, 2],\n",
       " 'develop': [0, 1, 3, 4, 5, 8, 9],\n",
       " 'concentration': [0, 1, 3, 8],\n",
       " 'elicit': [0, 9],\n",
       " 'betacoronaviruse': [0, 9],\n",
       " 'category': [0, 1, 2, 8],\n",
       " 'associate': [0, 1, 2, 3, 7, 8, 9],\n",
       " 'quick': [0],\n",
       " 'recovery': [0, 1, 8],\n",
       " 'symptomsThe': [0],\n",
       " 'author': [0, 1, 2, 3, 6, 7, 8, 9],\n",
       " 'speculate': [0],\n",
       " 'immunesystem': [0],\n",
       " 'player': [0],\n",
       " 'generate': [0, 9],\n",
       " 'betacoronaviru': [0],\n",
       " 'doctor': [0, 9],\n",
       " 'tend': [0],\n",
       " 'Juanacatlan': [0],\n",
       " 'MexicoCredit': [0],\n",
       " 'Ulises': [0],\n",
       " 'RuizAFPGetty15': [0],\n",
       " 'common': [0, 7, 8, 9],\n",
       " 'asthma': [0],\n",
       " 'medicine': [0, 5, 6, 7, 8],\n",
       " 'shave': [0],\n",
       " 'illnessA': [0],\n",
       " 'trial': [0, 1, 2, 3, 4, 8, 9],\n",
       " '4600': [0],\n",
       " 'inhalable': [0],\n",
       " 'medication': [0],\n",
       " 'disease': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " '3': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'daysThe': [0],\n",
       " 'drug': [0, 3, 6, 9],\n",
       " 'budesonide': [0],\n",
       " 'inexpensive': [0, 1],\n",
       " 'widely': [0, 1, 9],\n",
       " 'available': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'steroid': [0, 6],\n",
       " 'Christopher': [0],\n",
       " 'Butler': [0],\n",
       " 'Richard': [0],\n",
       " 'Hobbs': [0],\n",
       " 'Oxford': [0, 9],\n",
       " 'hospitalize': [0, 1, 2, 3, 4, 8],\n",
       " 'PRINCIPLE': [0],\n",
       " 'Collaborative': [0],\n",
       " 'Group': [0, 8, 9],\n",
       " 'httpsdoiorgf6hf': [0],\n",
       " 'participant': [0, 8],\n",
       " '50': [0, 1, 2, 5, 8, 9],\n",
       " 'condition': [0, 1, 2, 3, 5, 8],\n",
       " 'complication': [0, 3, 8],\n",
       " 'assign': [0, 1, 2, 3, 4],\n",
       " 'serve': [0],\n",
       " 'control': [0, 2, 3, 7, 9],\n",
       " 'group': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'none': [0, 1, 4],\n",
       " 'take': [0, 1, 5, 6, 7, 8, 9],\n",
       " 'placebo': [0, 1, 2, 3, 4],\n",
       " 'both': [0, 1],\n",
       " 'investigator': [0, 2, 3, 4, 8],\n",
       " 'drugthose': [0],\n",
       " 'twice': [0],\n",
       " 'daily': [0, 1],\n",
       " 'end': [0, 1, 3, 4, 5, 7],\n",
       " 'three': [0, 1, 3, 4, 6, 8, 9],\n",
       " 'man': [0, 2, 6, 8, 9],\n",
       " 'Israel': [0],\n",
       " 'vaccinecredit': [0],\n",
       " 'Amir': [0],\n",
       " 'LevyGetty14': [0],\n",
       " 'vaccination': [0, 5, 9],\n",
       " 'scheme': [0],\n",
       " 'controlIsraelxe2x80x99s': [0],\n",
       " 'worldleade': [0],\n",
       " 'programme': [0],\n",
       " 'seem': [0, 7, 9],\n",
       " 'worrying': [0],\n",
       " 'baymore': [0],\n",
       " '60': [0, 1, 2, 7, 8],\n",
       " 'Pfizerxe2x80x99s': [0],\n",
       " 'plummet': [0],\n",
       " 'Kingdom': [0, 9],\n",
       " 'circulate': [0, 9],\n",
       " 'determine': [0, 1, 2, 4, 8, 9],\n",
       " 'lead': [0, 2, 3, 4, 7, 9],\n",
       " 'Adi': [0],\n",
       " 'Stern': [0],\n",
       " 'Tel': [0],\n",
       " 'Aviv': [0],\n",
       " 'Shay': [0],\n",
       " 'BenShachar': [0],\n",
       " 'Clalit': [0],\n",
       " 'Research': [0, 3, 4, 6, 8, 9],\n",
       " 'Ramat': [0],\n",
       " 'Gan': [0],\n",
       " 'analyse': [0, 2, 3, 8],\n",
       " 'xe2x80x98breakthrough': [0],\n",
       " 'infectionsxe2x80x99': [0],\n",
       " 'record': [0, 1, 8, 9],\n",
       " 'hundred': [0],\n",
       " 'T': [0, 8, 9],\n",
       " 'Kustin': [0],\n",
       " 'httpsdoiorgf6g3': [0],\n",
       " 'Multitude': [0],\n",
       " 'threat': [0, 7],\n",
       " 'unclearalmost': [0],\n",
       " '250': [0, 1, 2],\n",
       " 'breakthrough': [0],\n",
       " 'recommended': [0],\n",
       " 'match': [0, 4, 6, 7, 8],\n",
       " 'characteristic': [0, 1, 2, 3, 6, 8, 9],\n",
       " 'comparison': [0, 1, 4, 8, 9],\n",
       " 'partially': [0, 9],\n",
       " 'immunized': [0, 1],\n",
       " 'slightly': [0, 4],\n",
       " 'likely': [0, 2, 7, 8, 9],\n",
       " 'cause': [0, 1, 2, 4, 5, 6, 7, 8, 9],\n",
       " 'B117': [0],\n",
       " 'peopleThe': [0],\n",
       " '149': [0, 2],\n",
       " 'eight': [0, 4, 9],\n",
       " 'b1351': [0],\n",
       " 'South': [0, 2, 9],\n",
       " 'Africa': [0, 2, 9],\n",
       " 'just': [0],\n",
       " 'suggesting': [0],\n",
       " 'less': [0, 1, 4, 8, 9],\n",
       " 'variantsrate': [0],\n",
       " 'remain': [0, 1, 7, 8, 9],\n",
       " 'rise': [0, 9],\n",
       " 'intervention': [0, 1, 4, 8],\n",
       " 'check': [0],\n",
       " 'rapid': [0, 1, 3, 6, 7, 9],\n",
       " 'process': [0, 6],\n",
       " 'school': [0, 5, 8],\n",
       " 'Halifax': [0],\n",
       " 'ScarffAFPGetty12': [0],\n",
       " 'value': [0, 4, 8, 9],\n",
       " 'stop': [0, 1],\n",
       " 'COVIDxe2x80x99s': [0],\n",
       " 'spreadrapid': [0],\n",
       " 'simulation': [0, 9],\n",
       " 'incorporate': [0, 9],\n",
       " '35': [0, 2, 4, 8, 9],\n",
       " 'million': [0, 2, 4, 8, 9],\n",
       " 'coronaviru': [0, 1, 3, 4, 6, 8, 9],\n",
       " 'testsrapid': [0],\n",
       " 'perform': [0, 2, 3, 4, 9],\n",
       " 'handheld': [0],\n",
       " 'kit': [0, 1],\n",
       " 'antigen': [0, 9],\n",
       " 'lateralflow': [0],\n",
       " 'device': [0],\n",
       " 'bolster': [0],\n",
       " 'testandtrace': [0],\n",
       " 'slow': [0, 3, 4, 9],\n",
       " 'goldstandard': [0],\n",
       " 'polymerase': [0],\n",
       " 'chain': [0, 9],\n",
       " 'reaction': [0, 3, 4],\n",
       " 'PCR': [0, 4, 6],\n",
       " 'testsDavid': [0],\n",
       " 'Eyre': [0],\n",
       " 'Tim': [0],\n",
       " 'Peto': [0],\n",
       " 'John': [0, 9],\n",
       " 'Radcliffe': [0],\n",
       " 'Hospital': [0, 6, 7, 8, 9],\n",
       " 'contracttrace': [0],\n",
       " 'collect': [0, 1, 2, 3, 4, 8, 9],\n",
       " '28': [0, 1, 2, 4, 6, 8, 9],\n",
       " 'February': [0, 9],\n",
       " 'L': [0, 6, 7, 8, 9],\n",
       " 'Y': [0, 6, 7, 8, 9],\n",
       " 'W': [0, 8, 9],\n",
       " 'Lee': [0, 9],\n",
       " 'httpsdoiorgf5jc': [0],\n",
       " '25': [0, 1, 2, 3, 4, 6, 8, 9],\n",
       " 'come': [0, 7, 9],\n",
       " 'themthe': [0],\n",
       " 'performance': [0],\n",
       " 'sensitive': [0],\n",
       " 'infected': [0, 1, 3, 9],\n",
       " 'body': [0, 2],\n",
       " 'levelsinfection': [0],\n",
       " 'reviewedThe': [0],\n",
       " 'Sputnik': [0],\n",
       " 'V': [0, 6, 9],\n",
       " 'adenovirus': [0],\n",
       " 'cold': [0, 9],\n",
       " 'shuttle': [0],\n",
       " 'peoplecredit': [0],\n",
       " 'Yelena': [0],\n",
       " 'AfoninaTASSGetty9': [0],\n",
       " 'fastspreading': [0],\n",
       " 'variantA': [0],\n",
       " 'evade': [0],\n",
       " 'covid19many': [0],\n",
       " 'Gamelaya': [0],\n",
       " 'Centre': [0, 9],\n",
       " 'Epidemiology': [0, 8, 9],\n",
       " 'Microbiology': [0],\n",
       " 'Moscow': [0],\n",
       " 'target': [0, 1, 3, 4, 8, 9],\n",
       " 'host': [0, 6, 9],\n",
       " 'worry': [0],\n",
       " 'may': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'ineffective': [0],\n",
       " 'spikeencoding': [0],\n",
       " 'genebenhur': [0],\n",
       " 'Icahn': [0],\n",
       " 'Medicine': [0, 5, 6, 7, 8, 9],\n",
       " 'Mount': [0],\n",
       " 'Sinai': [0],\n",
       " 'New': [0, 5, 6, 8],\n",
       " 'York': [0],\n",
       " 'City': [0, 8, 9],\n",
       " 'obtain': [0, 1, 3, 4, 6, 8, 9],\n",
       " 'antibodyladen': [0],\n",
       " 'blood': [0, 1, 2, 8],\n",
       " 'serum': [0, 1, 3, 6, 8],\n",
       " '12': [0, 1, 3, 4, 6, 7, 8, 9],\n",
       " 'Ikegame': [0],\n",
       " 'httpsdoiorgf5h9': [0],\n",
       " 'benign': [0, 9],\n",
       " 'engineer': [0],\n",
       " 'certain': [0, 3, 6, 7, 8],\n",
       " 'variantsThe': [0],\n",
       " 'inhibit': [0, 9],\n",
       " 'equip': [0],\n",
       " 'B1351': [0],\n",
       " 'effectively': [0],\n",
       " 'overcome': [0],\n",
       " 'emergence': [0, 3, 9],\n",
       " 'require': [0, 4, 6, 8, 9],\n",
       " 'generation': [0, 9],\n",
       " 'blue': [0],\n",
       " 'SARSCoV2Credit': [0],\n",
       " 'Library8': [0],\n",
       " 'muscle': [0, 8],\n",
       " 'aside': [0, 5],\n",
       " 'potent': [0, 4],\n",
       " 'antibodiesfastspreading': [0],\n",
       " 'blunt': [0],\n",
       " 'vaccinesin': [0],\n",
       " 'spot': [0, 5, 8],\n",
       " 'pair': [0, 8],\n",
       " 'share': [0, 6, 9],\n",
       " 'affect': [0, 1, 2, 3, 5, 6, 9],\n",
       " 'B1427': [0],\n",
       " 'B1429': [0],\n",
       " '30': [0, 1, 2, 3, 6, 8, 9],\n",
       " 'country': [0, 1, 2, 9],\n",
       " 'state': [0, 1, 5, 8, 9],\n",
       " 'account': [0, 6, 7, 8, 9],\n",
       " 'sequence': [0, 1, 4, 9],\n",
       " 'CaliforniaTo': [0],\n",
       " 'well': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'gauge': [0],\n",
       " 'pose': [0, 6],\n",
       " 'David': [0, 9],\n",
       " 'Veesler': [0],\n",
       " 'Washington': [0],\n",
       " 'Seattle': [0],\n",
       " 'conduct': [0, 1, 2, 3, 4, 9],\n",
       " 'laboratory': [0, 2, 4, 8],\n",
       " 'variantsxe2x80x99': [0],\n",
       " 'elude': [0],\n",
       " 'infectionblocking': [0],\n",
       " 'neutralize': [0, 3, 4, 8, 9],\n",
       " 'McCallum': [0],\n",
       " 'bioRxiv': [0, 9],\n",
       " 'httpsdoiorgf5jq': [0],\n",
       " 'average': [0, 3, 9],\n",
       " 'spikeprotein': [0],\n",
       " 'b1427': [0],\n",
       " 'review': [0, 1, 2, 3, 4, 5, 7, 8, 9],\n",
       " 'hold': [0, 5],\n",
       " 'variantproof': [0],\n",
       " 'vaccinesXiaoying': [0],\n",
       " 'Shen': [0],\n",
       " 'Montefiori': [0],\n",
       " 'Duke': [0],\n",
       " 'Durham': [0],\n",
       " 'North': [0],\n",
       " 'Carolina': [0],\n",
       " 'separate': [0, 3, 7, 9],\n",
       " 'investigation': [0, 1, 6, 8],\n",
       " 'respond': [0, 8],\n",
       " 'X': [0, 7, 9],\n",
       " 'N': [0, 6, 7, 8, 9],\n",
       " 'Engl': [0, 6, 8],\n",
       " 'Med': [0, 6, 7, 8, 9],\n",
       " 'httpsdoiorgf5kc': [0],\n",
       " 'pit': [0],\n",
       " 'source': [0, 2],\n",
       " 'immunize': [0, 5],\n",
       " 'Novavax': [0],\n",
       " 'recover': [0, 1, 3, 4, 8],\n",
       " 'Laboratory': [0, 8],\n",
       " 'resistant': [0, 9],\n",
       " 'inhibition': [0],\n",
       " 'set': [0, 1, 3, 4, 8, 9],\n",
       " 'strain': [0, 9],\n",
       " 'pandemicThe': [0],\n",
       " 'reduction': [0, 1, 2, 3, 4, 8, 9],\n",
       " 'potency': [0],\n",
       " 'observe': [0, 1, 2, 3, 4, 6, 7, 8, 9],\n",
       " 'Current': [0, 9],\n",
       " 'highly': [0, 4, 6, 9],\n",
       " 'Montefiorixe2x80x99s': [0],\n",
       " 'saysdose': [0],\n",
       " 'Dxc3xa9cinesCharpieu': [0],\n",
       " 'FranceCredit': [0],\n",
       " 'JeanPhilippe': [0],\n",
       " 'KsiazekAFPGetty7': [0],\n",
       " 'last': [0, 1, 2, 4],\n",
       " 'monthsThe': [0],\n",
       " 'spur': [0],\n",
       " 'persist': [0, 4, 8, 9],\n",
       " 'six': [0, 1, 2, 6, 9],\n",
       " 'twodose': [0],\n",
       " 'Cambridge': [0],\n",
       " '94': [0, 2, 3, 8],\n",
       " 'learn': [0],\n",
       " 'whether': [0, 1, 2, 4, 8, 9],\n",
       " 'Mehul': [0, 9],\n",
       " 'Suthar': [0, 9],\n",
       " 'Emory': [0, 9],\n",
       " 'Decatur': [0],\n",
       " 'Georgia': [0],\n",
       " '33': [0, 2, 3, 8],\n",
       " 'phase': [0, 2, 3, 4, 5, 6, 8, 9],\n",
       " 'DoriaRose': [0],\n",
       " 'httpsdoiorgf5c6': [0],\n",
       " '2021three': [0],\n",
       " 'type': [0, 1, 2, 3, 8, 9],\n",
       " 'month': [0, 1, 3, 7, 8, 9],\n",
       " 'example': [0, 1, 8],\n",
       " 'modify': [0, 1, 2, 3, 8],\n",
       " 'monthshealthcare': [0],\n",
       " 'screen': [0, 1, 3, 9],\n",
       " 'Luanda': [0],\n",
       " 'sarscov2credit': [0],\n",
       " 'Ampe': [0],\n",
       " 'RogerioEPAEFEShutterstock6': [0],\n",
       " 'air': [0, 1, 2, 4],\n",
       " 'traveller': [0],\n",
       " 'yield': [0],\n",
       " 'bristling': [0],\n",
       " 'mutationsA': [0],\n",
       " 'Angola': [0],\n",
       " 'carry': [0, 6, 9],\n",
       " 'previously': [0, 4, 6, 7, 8, 9],\n",
       " 'identifiedA': [0],\n",
       " 'Tulio': [0],\n",
       " 'de': [0, 1, 8, 9],\n",
       " 'Oliveira': [0],\n",
       " 'KwaZuluNatal': [0],\n",
       " 'Durban': [0],\n",
       " 'Silvia': [0],\n",
       " 'Lutucuta': [0],\n",
       " 'Ministry': [0],\n",
       " 'fly': [0],\n",
       " 'Tanzania': [0],\n",
       " 'httpsdoiorgf48': [0],\n",
       " 'g': [0, 3, 9],\n",
       " 'name': [0],\n",
       " 'avoiv2': [0],\n",
       " '34': [0, 4, 8, 9],\n",
       " '14': [0, 2, 3, 4, 5, 6, 8, 9],\n",
       " 'cellsThe': [0],\n",
       " 'deserve': [0],\n",
       " 'escape': [0, 9],\n",
       " 'peoplexe2x80x99s': [0],\n",
       " 'reviewedChildren': [0],\n",
       " 'play': [0, 2],\n",
       " 'roughly': [0, 9],\n",
       " 'Guy': [0],\n",
       " 'privesgetty2': [0],\n",
       " 'nationxe2x80x99s': [0],\n",
       " 'race': [0, 2],\n",
       " 'kid': [0],\n",
       " 'toovaccinate': [0],\n",
       " 'stall': [0],\n",
       " 'communitylast': [0],\n",
       " 'December': [0, 2, 3, 8, 9],\n",
       " 'launch': [0],\n",
       " 'fast': [0, 9],\n",
       " 'world': [0],\n",
       " 'reach': [0, 1, 2, 4, 9],\n",
       " '9': [0, 1, 2, 3, 4, 7, 9],\n",
       " '16': [0, 1, 2, 3, 4, 8, 9],\n",
       " 'eligible': [0, 1, 2, 3, 8],\n",
       " 'jabTo': [0],\n",
       " 'ripple': [0],\n",
       " 'widespread': [0, 9],\n",
       " 'Tal': [0],\n",
       " 'Patalon': [0],\n",
       " 'Maccabi': [0],\n",
       " 'Healthcare': [0],\n",
       " 'Services': [0, 3],\n",
       " 'AvivYafo': [0],\n",
       " 'Roy': [0],\n",
       " 'Kishony': [0],\n",
       " 'Technion': [0],\n",
       " 'Technology': [0, 8],\n",
       " 'Haifa': [0],\n",
       " 'January': [0, 6, 7, 8, 9],\n",
       " '223': [0, 4],\n",
       " 'israeli': [0],\n",
       " 'O': [0, 9],\n",
       " 'Milman': [0],\n",
       " 'httpsdoiorgf4d7': [0],\n",
       " 'examine': [0, 1, 2, 3, 4, 9],\n",
       " 'relationship': [0],\n",
       " '3week': [0],\n",
       " 'interval': [0, 1, 2, 3, 4, 9],\n",
       " 'laterThe': [0],\n",
       " 'drop': [0, 9],\n",
       " 'proportionally': [0],\n",
       " 'percentage': [0, 1, 2, 3, 4, 8, 9],\n",
       " 'warn': [0],\n",
       " 'influence': [0, 9],\n",
       " 'though': [0, 9],\n",
       " 'reviewedparticle': [0],\n",
       " 'purple': [0, 9],\n",
       " 'speckle': [0],\n",
       " 'greencredit': [0],\n",
       " 'NIAIDNational': [0],\n",
       " 'Library30': [0],\n",
       " 'multitalente': [0],\n",
       " 'responseantibodie': [0],\n",
       " '501YV2': [0],\n",
       " 'variantsSouth': [0],\n",
       " 'Africaxe2x80x99s': [0],\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dictionnaire # chaque terme, suivi des documents dans lesquels ils apparaissent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 4 — Implementation d’un algorithme de recherche d’information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionnaire.insert(4,'% du texte',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Je choisi de compter le pourcentage de présence de ce mot dans le texte parmis tous les autres mots du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26859, 2162, 2553, 2576, 2050, 457, 3262, 1688, 9296, 6660]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_word_by_doc = []\n",
    "for i in range(0,10):\n",
    "    nb_word_by_doc.append(sum(Dictionnaire[Dictionnaire['Doc n°']==i][\"nb_fois\"]))\n",
    "\n",
    "nb_word_by_doc # nombre de mot du dictionnaire (répétition comprise) par document\n",
    "#la position représente l'ID du doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Doc n°</th>\n",
       "      <th>nb_fois</th>\n",
       "      <th>nb_de_Doc</th>\n",
       "      <th>% du texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.13031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0.052124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientific</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milestonesSkip</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>COUNTER</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16955</th>\n",
       "      <td>ISSN</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16956</th>\n",
       "      <td>00368075back</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>topterm</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958</th>\n",
       "      <td>PolicyAccessibility</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16959 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Term Doc n° nb_fois nb_de_Doc % du texte\n",
       "0                    COVID      0      35         4    0.13031\n",
       "1                 research      0      19         4    0.07074\n",
       "2                     year      0      14         8   0.052124\n",
       "3               scientific      0       2         1   0.007446\n",
       "4           milestonesSkip      0       1         1   0.003723\n",
       "...                    ...    ...     ...       ...        ...\n",
       "16954              COUNTER      9       1         1   0.015015\n",
       "16955                 ISSN      9       1         1   0.015015\n",
       "16956         00368075back      9       1         1   0.015015\n",
       "16957              topterm      9       1         1   0.015015\n",
       "16958  PolicyAccessibility      9       1         1   0.015015\n",
       "\n",
       "[16959 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajout du pourcentage de présence du term parmi tous les termes du dictionnaire présents dans le document\n",
    "for i in range(len(Dictionnaire)) : \n",
    "    Dictionnaire.at[i, \"% du texte\"] = Dictionnaire[\"nb_fois\"][i]/ nb_word_by_doc[Dictionnaire[\"Doc n°\"][i]]*100\n",
    "\n",
    "Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Début des requêtes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requêtes booléennes :  \n",
    "1. desease AND severe  \n",
    "2. antibody AND plasma AND (cells OR receptors) \n",
    "3. antimalarial drugs OR antiviral agents OR immunomodulators \n",
    "4. NOT plasma AND risk of infection AND NOT restrictions \n",
    "5. (older adults AND antibodies) AND (genomes OR variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Je définie une fonction pour réaliser mes requêtes \n",
    "* Pour le cas \"risk of injection\", je choisi de chercher dans les docs la chaine de character \"risk of injection\", car utiliser mon dictionnaire serait éroné\n",
    "* En effet, les mots étant tokenizés, en faisant une requete qui prend les docs contenant risk et of et injection, n'aurait pas nécessairement ces mots à la suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def Request(texte): \n",
    "    print(\"-----\", texte, \"------\")\n",
    "    res = [texte]\n",
    "    list_req = nlp(texte)\n",
    "    \n",
    "    words = []\n",
    "    op = []\n",
    "    result = pd.DataFrame(columns={\"Document\", \"Pourcentage des requêtes\"})\n",
    "\n",
    "\n",
    "    for req in list_req:\n",
    "        if req.text != \"AND\" and req.text != \"OR\" and req.text != \"NOT\":\n",
    "            words.append(str(req.lemma_))\n",
    "        else : \n",
    "            op.append(str(req))\n",
    "\n",
    "            \n",
    "    # ---- 1 - disease AND severe ----\n",
    "    if op == [\"AND\"]: \n",
    "        res.append(index_dictionnaire[words[0]] and \n",
    "            index_dictionnaire[words[1]]\n",
    "        )\n",
    "        for doc in res[1:][0] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "\n",
    "    #---- 2 - antibody AND plasma AND cells OR receptor ----\n",
    "    if op == [\"AND\",\"AND\",\"OR\"] and len(words)==4 : \n",
    "        res.append(index_dictionnaire[words[0]] and \n",
    "            index_dictionnaire[words[1]] and\n",
    "            (index_dictionnaire[words[2]] or\n",
    "            index_dictionnaire[words[3]] )\n",
    "        )\n",
    "        for doc in res[1:][0] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[2]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[3]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #---- 3 - antimalarial drugs OR antiviral agents OR immunomodulators ----\n",
    "    if op == [\"OR\", \"OR\"]:\n",
    "        word_str = words[0] + \" \" + words[1]\n",
    "        word_str2 = words[2] + \" \" + words[3]\n",
    "\n",
    "        for doc in range(0,10):\n",
    "            if (word_str in documents['Text'][doc]) or (word_str2 in documents['Text'][doc]) or (words[4] in documents['Text'][doc]):\n",
    "                res.append(doc)\n",
    "        \n",
    "        for doc in res[1:] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[2]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "\n",
    "    # ---- 4 - NOT plasma AND risk of injection AND NOT restrictions ----\n",
    "    if op == [\"NOT\", \"AND\", \"AND\", \"NOT\"] :\n",
    "        word_str = words[1] + \" \" + words[2] + \" \" + words[3]\n",
    "        for doc in range(0,10):\n",
    "            if word_str in documents['Text'][doc] and doc not in index_dictionnaire[words[0]] and doc not in index_dictionnaire[words[4]]:\n",
    "                res.append(doc)\n",
    "\n",
    "#---- 5 - olders adults AND antibodies AND genomes OR variant ----\n",
    "    if op == [\"AND\",\"AND\",\"OR\"] and len(words)!=4:\n",
    "        word_str = words[0] + \" \" + words[1]\n",
    "        for doc in range(0,10):\n",
    "            if word_str in documents['Text'][doc] and doc in index_dictionnaire[words[2]] and doc in (index_dictionnaire[words[3]] or index_dictionnaire[words[4]]):\n",
    "                res.append(doc)\n",
    "\n",
    "        for doc in res[1:] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[2]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[3]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[4]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    result = result.sort_values(by=[\"Pourcentage des requêtes\"],ascending=False)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lancement des requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- disease AND severe ------\n",
      "   Pourcentage des requêtes  Document\n",
      "1                  1.063830       1.0\n",
      "5                  0.797057       6.0\n",
      "6                  0.462565       8.0\n",
      "2                  0.391696       2.0\n",
      "7                  0.390390       9.0\n",
      "4                  0.390244       4.0\n",
      "0                  0.137756       0.0\n",
      "3                  0.116460       3.0\n"
     ]
    }
   ],
   "source": [
    "request1 = Request(\"disease AND severe\")\n",
    "request1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- antibody AND plasma AND cells OR receptors ------\n",
      "   Pourcentage des requêtes  Document\n",
      "1                  1.397516       3.0\n",
      "0                  1.046204       0.0\n",
      "4                  0.398021       8.0\n",
      "2                  0.341463       4.0\n",
      "5                  0.225225       9.0\n",
      "3                  0.030656       6.0\n"
     ]
    }
   ],
   "source": [
    "request2 = Request(\"antibody AND plasma AND cells OR receptors\")\n",
    "request2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- antimalarial drugs OR antiviral agents OR immunomodulators ------\n",
      "   Pourcentage des requêtes  Document\n",
      "2                  0.048780       4.0\n",
      "0                  0.003723       0.0\n",
      "1                  0.000000       2.0\n"
     ]
    }
   ],
   "source": [
    "request3 = Request(\"antimalarial drugs OR antiviral agents OR immunomodulators\")\n",
    "request3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pas de résultat pour la requete 4 malgré que je parcours les fichiers pour trouver \"risk of injection\" (mais je n'ai pas retransformé tout le texte en lemme, il aurait fallu que je fasse des combinaisons de mots à analyser en lemme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- NOT plasma AND risk of injection AND NOT restrictions ------\n",
      "Empty DataFrame\n",
      "Columns: [Pourcentage des requêtes, Document]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "request4 = Request(\"NOT plasma AND risk of injection AND NOT restrictions\")\n",
    "request4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- older adults AND antibodies AND genomes OR variant ------\n",
      "Empty DataFrame\n",
      "Columns: [Pourcentage des requêtes, Document]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "request5 = Request(\"older adults AND antibodies AND genomes OR variant\")\n",
    "request5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Autres tests complémentaires : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- older AND adults ------\n",
      "   Pourcentage des requêtes  Document\n",
      "1                  0.462535       1.0\n",
      "2                  0.218818       5.0\n",
      "5                  0.120120       9.0\n",
      "0                  0.111694       0.0\n",
      "3                  0.000000       7.0\n",
      "4                  0.000000       8.0\n",
      "None\n",
      "----- older AND adults AND antibodies OR disease ------\n",
      "   Pourcentage des requêtes  Document\n",
      "1                  0.462535       1.0\n",
      "4                  0.146341       4.0\n",
      "7                  0.120120       9.0\n",
      "2                  0.117509       2.0\n",
      "0                  0.111694       0.0\n",
      "3                  0.038820       3.0\n",
      "5                  0.000000       6.0\n",
      "6                  0.000000       8.0\n",
      "None\n",
      "----- antimalarial AND antiviral ------\n",
      "   Pourcentage des requêtes  Document\n",
      "3                  0.048780       4.0\n",
      "0                  0.003723       0.0\n",
      "1                  0.000000       2.0\n",
      "2                  0.000000       3.0\n",
      "4                  0.000000       8.0\n",
      "5                  0.000000       9.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Request(\"older AND adults\"))\n",
    "print(Request(\"older AND adults AND antibodies OR disease\"))\n",
    "print(Request(\"antimalarial AND antiviral\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requêtes complexes :  \n",
    "\n",
    "1. antibody treatments \n",
    "2. efficacy and safety of the treatments  \n",
    "3. family access to hospitals \n",
    "4. contact tracing results \n",
    "5. genomic analysis of SARS-CoV-2 disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def Request_Complexe(texte): \n",
    "    print(\"-----\", texte, \"------\")\n",
    "    res = [texte]\n",
    "    list_req = nlp(texte)\n",
    "    \n",
    "    words = []\n",
    "    op = []\n",
    "    result = pd.DataFrame(columns={\"Document\", \"Pourcentage des requêtes\"})\n",
    "\n",
    "\n",
    "    for req in list_req:\n",
    "        if req.text != \"and\" and req.text != \"of\" and req.text != \"the\" and req.text != \"to\":\n",
    "            words.append(str(req.lemma_))\n",
    "\n",
    "            \n",
    "    # ---- antibody treatments \n",
    "    if len(words) == 2: \n",
    "        res.append(index_dictionnaire[words[0]] and \n",
    "            index_dictionnaire[words[1]]\n",
    "        )\n",
    "        for doc in res[1:][0] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "\n",
    "    #---- efficacy and safety of the treatments\n",
    "    #---- family access to hospitals\n",
    "    #---- contact tracing results\n",
    "\n",
    "    if len(words) == 3: \n",
    "        res.append(index_dictionnaire[words[0]] and \n",
    "            index_dictionnaire[words[1]] and \n",
    "            index_dictionnaire[words[2]] \n",
    "        )\n",
    "        for doc in res[1:][0] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[2]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "\n",
    "    #---- genomic analysis of SARS-CoV-2 disease\n",
    "    if len(words) == 4: \n",
    "        res.append(index_dictionnaire[words[0]] and \n",
    "            index_dictionnaire[words[1]] and \n",
    "            (index_dictionnaire[words[2]] or index_dictionnaire['COVID']) and\n",
    "            index_dictionnaire[words[3]] \n",
    "\n",
    "        )\n",
    "        for doc in res[1:][0] :\n",
    "            lign = Dictionnaire.loc[(Dictionnaire['Term']== words[0]) & (Dictionnaire['Doc n°']== doc),:]\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[1]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[2]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "            lign.append(Dictionnaire.loc[(Dictionnaire['Term']== words[3]) & (Dictionnaire['Doc n°']== doc),:])\n",
    "\n",
    "            result = result.append({\"Document\":doc,\"Pourcentage des requêtes\": lign['% du texte'].sum() }, ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    result = result.sort_values(by=[\"Pourcentage des requêtes\"],ascending=False)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- antibody treatments ------\n",
      "   Pourcentage des requêtes  Document\n",
      "3                  1.397516       3.0\n",
      "0                  1.046204       0.0\n",
      "1                  0.601295       1.0\n",
      "6                  0.398021       8.0\n",
      "4                  0.341463       4.0\n",
      "7                  0.225225       9.0\n",
      "2                  0.078339       2.0\n",
      "5                  0.030656       6.0\n"
     ]
    }
   ],
   "source": [
    "Request_Complexe(\"antibody treatments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- efficacy and safety of the treatments ------\n",
      "   Pourcentage des requêtes  Document\n",
      "2                  0.470035       2.0\n",
      "3                  0.155280       3.0\n",
      "4                  0.146341       4.0\n",
      "7                  0.105105       9.0\n",
      "1                  0.046253       1.0\n",
      "0                  0.022339       0.0\n",
      "5                  0.000000       6.0\n",
      "6                  0.000000       8.0\n"
     ]
    }
   ],
   "source": [
    "Request_Complexe(\"efficacy and safety of the treatments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- family access to hospitals ------\n",
      "   Pourcentage des requêtes  Document\n",
      "5                  1.184834       7.0\n",
      "0                  0.018616       0.0\n",
      "7                  0.015015       9.0\n",
      "6                  0.010757       8.0\n",
      "1                  0.000000       1.0\n",
      "2                  0.000000       2.0\n",
      "3                  0.000000       4.0\n",
      "4                  0.000000       6.0\n"
     ]
    }
   ],
   "source": [
    "Request_Complexe(\"family access to hospitals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- contact tracing results ------\n",
      "   Pourcentage des requêtes  Document\n",
      "0                  0.137756       0.0\n",
      "8                  0.060060       9.0\n",
      "7                  0.043029       8.0\n",
      "2                  0.039170       2.0\n",
      "6                  0.030656       6.0\n",
      "1                  0.000000       1.0\n",
      "3                  0.000000       3.0\n",
      "4                  0.000000       4.0\n",
      "5                  0.000000       5.0\n"
     ]
    }
   ],
   "source": [
    "Request_Complexe(\"contact tracing results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pas de réponse pour cette request, probablement à cause de SARS-CoV-2 ou alors parce qu'il n'y a pas cette combinaison dans les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- genomic analysis of SARS-CoV-2 disease ------\n",
      "Empty DataFrame\n",
      "Columns: [Pourcentage des requêtes, Document]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "Request_Complexe('genomic analysis of SARS-CoV-2 disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in doc  0\n",
      "Not in doc  1\n",
      "Not in doc  2\n",
      "Not in doc  3\n",
      "Not in doc  4\n",
      "Not in doc  5\n",
      "Not in doc  6\n",
      "Not in doc  7\n",
      "Not in doc  8\n",
      "Not in doc  9\n"
     ]
    }
   ],
   "source": [
    "word_str = \"genomic analysis of SARS-CoV-2 disease\"\n",
    "for doc in range(0,10):\n",
    "            if (word_str in documents['Text'][doc]):\n",
    "                print(doc)\n",
    "            else :\n",
    "                print(\"Not in doc \", doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "* Les n-grams auraient été plus utiles mais je m'en suis rendue compte trop tard et reprendre tout le code serait vraiment trop long\n",
    "* Cependant pour la plupart des requetes on a les résultats\n",
    "* Il est également possible d'obtenir les résultats en reformulant les requetes\n",
    "Par exemple : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- genomic analysis of COVID ------\n",
      "   Pourcentage des requêtes  Document\n",
      "0                  0.029785       0.0\n",
      "1                  0.000000       7.0\n",
      "2                  0.000000       8.0\n",
      "3                  0.000000       9.0\n",
      "None\n",
      "----- genomic analysis of SARS-CoV-2 disease ------\n",
      "Empty DataFrame\n",
      "Columns: [Pourcentage des requêtes, Document]\n",
      "Index: []\n",
      "None\n",
      "----- genomic analysis of COVID disease ------\n",
      "   Pourcentage des requêtes  Document\n",
      "0                  0.029785       0.0\n",
      "1                  0.000000       1.0\n",
      "2                  0.000000       2.0\n",
      "3                  0.000000       3.0\n",
      "4                  0.000000       4.0\n",
      "5                  0.000000       5.0\n",
      "6                  0.000000       6.0\n",
      "7                  0.000000       7.0\n",
      "8                  0.000000       8.0\n",
      "9                  0.000000       9.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Request_Complexe('genomic analysis of COVID'))\n",
    "print(Request_Complexe('genomic analysis of SARS-CoV-2 disease'))\n",
    "print(Request_Complexe('genomic analysis of COVID disease'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "636cdaddf8278713ac0f8899dff8f68cf32cd8ae3d3514f61665594349bacd03"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
